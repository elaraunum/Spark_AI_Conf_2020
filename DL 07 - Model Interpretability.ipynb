{"cells":[{"cell_type":"markdown","source":["d-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 1200px\">\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n# Model Interpretability\n\n<img style=\"width:20%\" src=\"https://files.training.databricks.com/images/Limes.jpg\" > No, we're not talking about limes.\n\nWe're talking about [Local Interpretable Model-Agnostic Explanations](https://github.com/marcotcr/lime).\n\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) In this lesson you:<br>\n - Use LIME and SHAP to understand which features are most important in the model's prediction for that data point"],"metadata":{}},{"cell_type":"code","source":["%pip install shap==0.35.0"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["%pip install lime==0.2.0.0"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["%run \"./Includes/Classroom-Setup\""],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["Don't forget you need to scale your data because the model was trained on scaled data!"],"metadata":{}},{"cell_type":"code","source":["from sklearn.datasets import load_boston\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nboston_housing = load_boston() \n\n# split 80/20 train-test\nX_train, X_test, y_train, y_test = train_test_split(boston_housing.data,\n                                                    boston_housing.target,\n                                                    test_size=0.2,\n                                                    random_state=1)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\nprint(boston_housing.DESCR)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["## Load in Saved Model"],"metadata":{}},{"cell_type":"code","source":["from tensorflow.keras.models import load_model\n\nfilepath = \"/dbfs/mnt/training/bostonhousing/model.hdf5\"\n\nmodel = load_model(filepath)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["### Using LIME for Model Explanation\nWe can use the [LIME](https://github.com/marcotcr/lime) library to provide explanations of individual predictions.\n\n![](https://raw.githubusercontent.com/marcotcr/lime/master/doc/images/lime.png)"],"metadata":{}},{"cell_type":"code","source":["import lime\nfrom lime.lime_tabular import LimeTabularExplainer\n\nhelp(LimeTabularExplainer)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["###Interpreting Results\nLIME explains the impact of each feature on the prediction, and tabular explainers need a training set. \n\nThe reason for this is because we compute statistics on each feature (column). If the feature is numerical, we compute the mean and std, and discretize it into quartiles."],"metadata":{}},{"cell_type":"code","source":["def model_predict(input):\n  \"\"\"\n  Convert keras prediction output to LIME compatible form. (Needs to output a 1 dimensional array)\n  \"\"\"\n  return model.predict(input).flatten()\n\nexplainer = LimeTabularExplainer(X_train, feature_names=boston_housing.feature_names, class_names=[\"price\"], mode=\"regression\")\n# NOTE: In order to pass in categorical_features, they all need to be ints"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["From the LIME docs:\n\n0. First, we generate neighborhood data by randomly hiding features from the instance. \n0. We then learn locally weighted linear models on this neighborhood data to explain each of the classes in an interpretable way."],"metadata":{}},{"cell_type":"code","source":["exp = explainer.explain_instance(X_test[0], model_predict, num_features=10)\nprint(f\"True value: {y_test[0]}\")\nprint(f\"Local predicted value: {exp.predicted_value}\")"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["## Which features are most important?"],"metadata":{}},{"cell_type":"code","source":["displayHTML(exp.as_html())"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":["Positive correlation: \n0. `RM` (average number of rooms per dwelling) \n0. `CRIM` (per capita crime rate by town) - below \"average\"\n0. `LSTAT` (% lower status of the population)\n0. `B`     (1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town)\n0. `TAX`   (full-value property-tax rate per $10,000)\n0. `INDUS` (proportion of non-retail business acres per town)\n\nNegative correlation:\n0. `CHAS` (Charles River dummy variable = 1 if tract bounds river; 0 otherwise)\n0. `ZN` (proportion of residential land zoned for lots over 25,000 sq.ft.)\n0. `RAD` (index of accessibility to radial highways)\n0. `PTRATIO`  (pupil-teacher ratio by town)\n\nDo these make sense?"],"metadata":{}},{"cell_type":"code","source":["display(exp.as_pyplot_figure().tight_layout())"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["Let's get those values as a list."],"metadata":{}},{"cell_type":"code","source":["exp.as_list()"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["## SHAP\n\nSHAP ([SHapley Additive exPlanations](https://github.com/slundberg/shap)) is another approach to explain the output of a machine learning model. See the [SHAP NIPS](http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions) paper for details, and Christoph Molnar's book chapter on [Shapley Values](https://christophm.github.io/interpretable-ml-book/shapley.html).\n\n![](https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/shap_diagram.png)\n\nGreat [blog post](https://blog.dominodatalab.com/shap-lime-python-libraries-part-1-great-explainers-pros-cons/) comparing LIME to SHAP. SHAP provides greater theoretical guarantees than LIME, but at the cost of additional compute."],"metadata":{}},{"cell_type":"code","source":["import shap\n\nhelp(shap.DeepExplainer)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["# from IPython.core.display import display, HTML\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nshap.initjs()\nshap_explainer = shap.DeepExplainer(model, X_train[:200])\nshap_values = shap_explainer.shap_values(X_test[0:1])\ny_pred = model.predict(X_test[0:1])\nprint(f\"Actual price: {y_test[0]}, Predicted price: {y_pred[0][0]}\")\n                   \n# Saving to File b/c can't display IFrame directly in Databricks: https://github.com/slundberg/shap/issues/101\nfile_path = \"shap.html\"\nshap.save_html(file_path, shap.force_plot(shap_explainer.expected_value[0].numpy(), \n                                          shap_values[0], \n                                          X_test[0:1],\n                                          feature_names=boston_housing.feature_names, \n                                          show=False))"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":["## Visualize\n\n* Red pixels increase the model's output while blue pixels decrease the output.\n\nHere's a great [article](https://christophm.github.io/interpretable-ml-book/shapley.html) discussing how SHAP works under the hood."],"metadata":{}},{"cell_type":"code","source":["import codecs\n\nf = codecs.open(file_path, \"r\")\ndisplayHTML(f.read())"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":["The values on the bottom show the true values of `X_test[0]`."],"metadata":{}},{"cell_type":"code","source":["import pandas as pd\n\npd.DataFrame(X_test[0], boston_housing.feature_names, [\"features\"])"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":["This says that, overall, factors like negative LSTAT had the most positive effect on predicted housing price, while ZN had the most negative, among others.\n```\n- ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n- AGE      proportion of owner-occupied units built prior to 1940\n- PTRATIO  pupil-teacher ratio by town\n- RAD      index of accessibility to radial highways\n- CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n\n- LSTAT    % lower status of the population\n- RM       average number of rooms per dwelling\n- INDUS    proportion of non-retail business acres per town\n- TAX      full-value property-tax rate per $10,000\n- B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n- CRIM     per capita crime rate by town\n- NOX      nitric oxides concentration (parts per 10 million)\n- DIS      weighted distances to five Boston employment centres\n```"],"metadata":{}},{"cell_type":"markdown","source":["Let's see what the values corresponding to each feature are."],"metadata":{}},{"cell_type":"code","source":["shap_features = pd.DataFrame(shap_values[0][0], boston_housing.feature_names, [\"features\"])\nshap_features.sort_values(\"features\")"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":["The predicted value is the sum of the SHAP features + the average."],"metadata":{}},{"cell_type":"code","source":["print(f\"The predicted value is {shap_features.sum()[0] + shap_explainer.expected_value[0]}\")"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":["**Question**: How similar are the LIME predictions to the SHAP predictions?"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{}}],"metadata":{"name":"DL 07 - Model Interpretability","notebookId":1391719663531040},"nbformat":4,"nbformat_minor":0}
