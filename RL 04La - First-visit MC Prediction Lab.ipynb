{"cells":[{"cell_type":"markdown","source":["d-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 1200px\">\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["# Model-free Prediction (first-visit MC) \n\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) In this lab you learn:<br>\n - MC first visit update"],"metadata":{}},{"cell_type":"markdown","source":["### Problem statement ###\n\nConsider the random walk problem on a straight line (1D) with 7 states. States t1, a, b, c, d, e, t2. Assume two end states, t1 and t2, are terminal states. If you end up there, the episode is over. If you reach t2, you are rewarded $100. If you reach t1, you are rewarded $0. There is a 50% chance of going right or left when you are at state a, b, c, d and e."],"metadata":{}},{"cell_type":"markdown","source":["### Exercise ###\nAssume you start at state c and \\\\(\\gamma = 1\\\\). Use first-visit MC to estimate the value of each state."],"metadata":{}},{"cell_type":"code","source":["#ANSWER\nimport random\nimport numpy as np\nfrom statistics import mean\n\n\ndef monte_carlo(number_episodes, start_state='c'):\n  \"\"\"This function generates multiple episodes for the random walk problem.\"\"\"\n  \n  np.random.seed(1234)\n  # Initial transition list\n  episodes = []\n\n  \n  # Set up all states\n  states = ['t1','a', 'b', 'c', 'd', 'e', 't2']\n  \n  # Create samples of episodes\n  for i in range (number_episodes):\n    local_transitions = []\n    index = states.index(start_state)\n    local_transitions.append(index)\n    while True:\n      pick_action = np.random.randint(2, size = 1)[0]\n      # Go left\n      if pick_action == 0:\n        index -= 1\n      else:\n        index += 1\n      start_index = index\n      local_transitions.append(index)\n      if states[index] == 't1' or states[index] == 't2':\n        episodes.append(local_transitions)\n        break\n    \n  return(episodes) \n"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# ANSWER\ndef mc_first_visit(episodes):\n  \"\"\"This function calculate first-visit MC.\"\"\"\n\n  value_a = value_b = value_c = value_d = value_e = 0.5\n  reward_t2 = 100\n  reward_t1 = 0\n  \n  return_a = []\n  return_b = []\n  return_c = []\n  return_d = []\n  return_e = []\n  \n  # Loop through episodes and states to update return_a, return_b, return_c, return_d, return_e\n  \n  for i in range(len(episodes)):\n    if i % 1000 == 0:\n      print(f\"This is episode {i+1}\")\n    for j in list(set(episodes[i])):\n      \n      if j == 1.0 and episodes[i][-1] == 6:\n        return_a.append(reward_t2)\n        \n      elif j == 1.0 and episodes[i][-1] == 0: \n        return_a.append(reward_t1)\n        \n      \n      elif j == 2.0 and episodes[i][-1] == 6:\n        return_b.append(reward_t2)\n        \n      elif j == 2.0 and episodes[i][-1] == 0:\n        return_b.append(reward_t1)\n        \n        \n      elif j == 3.0 and episodes[i][-1] == 6:\n        return_c.append(reward_t2)\n        \n      elif j == 3.0 and episodes[i][-1] == 0:\n        return_c.append(reward_t1)\n        \n        \n      elif j == 4.0 and episodes[i][-1] == 6:\n        return_d.append(reward_t2)\n        \n      elif j == 4.0 and episodes[i][-1] == 0:\n        return_d.append(reward_t1)\n        \n        \n      elif j == 5.0 and episodes[i][-1] == 6:\n        return_e.append(reward_t2)\n        \n      elif j == 5.0 and episodes[i][-1] == 0:\n        return_e.append(reward_t1)\n      \n        \n    value_a = mean(return_a) if len(return_a) !=0  else value_a\n    value_b = mean(return_b) if len(return_b) !=0  else value_b\n    value_c = mean(return_c) if len(return_c) !=0  else value_c\n    value_d = mean(return_d) if len(return_d) !=0  else value_d\n    value_e = mean(return_e) if len(return_e) !=0  else value_e\n    \n  return [value_a, value_b, value_c, value_d, value_e]"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["# Test your code\nepisodes = monte_carlo(2000)\nvalue = mc_first_visit(episodes) \nvalue_expected = [15.0, 32.0, 49.0, 66.0, 82.0] \nnp.testing.assert_array_almost_equal(value, value_expected, err_msg = \"The values are incorrect\", decimal = 0)\n"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{}}],"metadata":{"name":"RL 04La - First-visit MC Prediction Lab","notebookId":2929930686998240},"nbformat":4,"nbformat_minor":0}
