{"cells":[{"cell_type":"markdown","source":["d-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 1200px\">\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["#Generative Adversarial Networks (GANs)\n<br/>\n0. The promise of deep learning is to discover *rich, hierarchical* models that represent probability distributions over the kinds of data encountered in artificial intelligence applications, such as natural images, audio waveforms containing speech, and symbols in natural language corpora. \n0. The most striking successes in deep learning have involved *discriminative models*, usually those that map a high-dimensional, rich sensory input to a class label. These striking successes have primarily been based on the *backpropagation and dropout algorithms*, using piecewise linear units which have a particularly well-behaved gradient.\n0. *Deep generative models* have had less of an impact, due to the difficulty of approximating many intractable probabilistic computations that arise in *maximum likelihood estimation* and related strategies, and due to difficulty of leveraging the benefits of piecewise linear units in the generative context. We propose a new generative model estimation procedure that sidesteps these difficulties.\n0. In *adversarial nets framework*, the *generative* model is pitted against an *adversary*: a discriminative model that learns to determine whether a sample is from the model distribution or the data distribution. The generative model can be thought of as analogous to a team of counterfeiters, trying to produce fake currency and use it without detection, while the discriminative model is analogous to the police, trying to detect the counterfeit currency. Competition in this game drives both teams to improve their methods until the counterfeits are indistiguishable from the genuine articles.\n<br/><br/>\nFor details see [GANs](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf)\n<br/><br/>\n![](https://files.training.databricks.com/images/gans.png)\n\nSource: https://lilianweng.github.io/lil-log/assets/images/GAN.png\n\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) In this lesson you:<br>\n - Learn about Generative and discriminative models\n - Get hands on experience on creating such models on California Housing dataset"],"metadata":{}},{"cell_type":"code","source":["%run \"./Includes/Classroom-Setup\""],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["from sklearn.datasets.california_housing import fetch_california_housing\nimport numpy as np\nimport pandas as pd\n\n# Fetch the data & create Pandas DataFrame\ncal_housing = fetch_california_housing()\nX, y = cal_housing.data, cal_housing.target\ndata = pd.concat([pd.DataFrame(X, columns=cal_housing.feature_names), pd.DataFrame(y, columns=[\"label\"])], axis=1)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["#### In order to implement GANs, we need to create three networks:\n0. Generative model\n0. Discriminative model\n0. GAN\n\n#### There are also multiple parameters/hyperparameters:\n0. Number of iterations\n0. Number of random sampling\n0. Numer of steps\n0. Shape of noise (here we use Gaussian noise with mean 0 and variance 1)"],"metadata":{}},{"cell_type":"code","source":["import tensorflow as tf\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.layers import Input, Dense, Dropout\nfrom tensorflow.keras.models import Model\n\n# Number of iterations \nepoch = 500\n\n# Sample size used to sample data and noise\nsample_size = 8\n\n# Step to train DIS\nstep_size = 10\n\n# Noise mean: we will be using Guassian noise \nmu = 1000\n\n# Noise variance\nsigma = 500\n\n# Dimension of the data (including label)\ndimension = 9"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["Define the GEN model. This part is an art."],"metadata":{}},{"cell_type":"code","source":["from tensorflow.keras import initializers\n\n# This function creates the generator model\ndef generative_model():\n  generative_model = models.Sequential()\n  generative_model.add(layers.Dense(20, input_dim=dimension, activation=\"relu\", kernel_initializer=initializers.RandomNormal(stddev=1)))\n  generative_model.add(layers.Dense(20, activation=\"relu\", kernel_initializer=initializers.RandomNormal(stddev=1)))\n  generative_model.add(layers.Dense(20, activation=\"relu\", kernel_initializer=initializers.RandomNormal(stddev=1)))\n  generative_model.add(layers.Dense(20, activation=\"relu\", kernel_initializer=initializers.RandomNormal(stddev=1)))\n  generative_model.add(layers.Dense(20, activation=\"relu\", kernel_initializer=initializers.RandomNormal(stddev=1)))\n  generative_model.add(layers.Dense(dimension, activation=\"linear\"))\n  return generative_model"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["Define the DIS model."],"metadata":{}},{"cell_type":"code","source":["# This function creates the discriminate network\ndef discriminative_model():\n  discriminative_model = models.Sequential()\n  discriminative_model.add(layers.Dense(10, input_dim=dimension, activation=\"relu\", kernel_initializer=initializers.RandomNormal(stddev=2)))\n  discriminative_model.add(Dropout(0.2))\n  discriminative_model.add(layers.Dense(10, activation=\"relu\", kernel_initializer=initializers.RandomNormal(stddev=2)))\n  discriminative_model.add(Dropout(0.2))\n  discriminative_model.add(layers.Dense(1, activation=\"sigmoid\", kernel_initializer=initializers.RandomNormal(stddev=2)))\n  discriminative_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n  return discriminative_model"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["# This function puts together Gen model and Dis model\ndef gan_model(gen,dis):\n  inp = Input(shape=(dimension,))\n  # Important: We do not want to train DIS\n  dis.trainable = False\n  merged = Model(inputs=inp, outputs=dis(gen(inp)))\n  merged.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n  return merged"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["# This function trains a GAN\ndef train_gans(epoch): \n  tf.keras.backend.clear_session()\n  np.random.seed(42)\n  tf.random.set_seed(42)\n  \n  # Create networks\n  dis_model = discriminative_model()\n  gen_model = generative_model()\n  gans_model = gan_model(gen_model,dis_model)\n\n  gans_loss = []\n  dis_loss = []\n\n  # Train GAN\n  for i in range(epoch):\n    for j in range(step_size):\n      noise = np.random.normal(mu, sigma, [sample_size, dimension])\n      data_sample = data.sample(sample_size)\n      gen_data = gen_model.predict(noise)\n      real_gen = np.concatenate((data_sample.iloc[:, 0:dimension], gen_data))\n      # Label smoothing\n      real_label = np.full((sample_size, 1), 0.9)\n      fake_label = np.full((sample_size, 1), 0.1)\n      real_gen_label = np.concatenate([real_label, fake_label])\n      dis_loss.append(dis_model.train_on_batch(real_gen, real_gen_label))\n\n    for k in range(step_size*2):\n      noise = np.random.normal(mu, sigma, [sample_size, dimension])\n      gans_loss.append(gans_model.train_on_batch(noise, real_label))\n\n    print(f\"This is epoch {i}. DIS' loss is {dis_loss[-1]} and GAN's loss is {gans_loss[-1]}\")\n  return (gen_model, dis_model)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["gen_model, dis_model = train_gans(epoch)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["Let's generate some fake data and compare the its distribution with the actual data."],"metadata":{}},{"cell_type":"code","source":["# This function returns the fake data generated by the generator model inside GAN\ndef generate_fake_data(gen_model):\n  tf.keras.backend.clear_session()\n  np.random.seed(42)\n  tf.random.set_seed(42)\n  noise = np.random.normal(mu, sigma, [20000, dimension])\n  fake_data_array = gen_model.predict(noise)\n  fake_data = pd.DataFrame(fake_data_array)\n  return fake_data"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["Since we are dealing with higher dimensional data, it is not possible to plot the joint distribution. Instead, we are going to look at the first two principal components. Here we consider multiple scenarios:\n0. Look at the two principal components of the real data \n0. Look at the two principal components of the real/fake data after 2 epochs\n0. Look at the two principal components of the real/fake data after 10 epochs"],"metadata":{}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nimport matplotlib.patches as mpatches\n\n# This function returns the PCA plots of two PCA components\ndef plot_pca(data, fake_dataset, original = False):  \n  # Standardize the data before applying PCA\n  scaler = StandardScaler()\n  transformed_real_data = scaler.fit_transform(data)\n  transformed_fake_data = scaler.fit_transform(fake_dataset)\n\n  # Find two principal components\n  pca = PCA(n_components=2)\n  principal_components_real_data = pca.fit_transform(transformed_real_data)\n  principal_components_fake_data = pca.fit_transform(transformed_fake_data)\n  principal_real_data = pd.DataFrame(data=principal_components_real_data, columns=[\"principal_component_1\", \"principal_component_2\"])\n  principal_fake_data = pd.DataFrame(data=principal_components_fake_data, columns=[\"principal_component_1\", \"principal_component_2\"])\n\n  # Plot the principle components of both datasets\n  if original == False:\n    # Plot the real data\n    plt.scatter(principal_real_data[\"principal_component_1\"], principal_real_data[\"principal_component_2\"], color=\"green\", s=70, alpha=0.3)\n    plt.title(\"2 principal components\")\n    plt.xlabel(\"component 1\")\n    plt.ylabel(\"component 2\")\n    green_patch = mpatches.Patch(color=\"green\", label=\"Real data\")\n    blue_patch = mpatches.Patch(color=\"blue\", label=\"Fake data\")\n    plt.legend(handles=[green_patch, blue_patch])\n    # Plot fake data\n    plt.scatter(principal_fake_data[\"principal_component_1\"], principal_fake_data[\"principal_component_2\"], color=\"blue\", s=70, alpha=0.3)\n    plt.title(\"2 principal components\")\n    plt.xlabel(\"component 1\")\n    plt.ylabel(\"component 2\")\n    green_patch = mpatches.Patch(color=\"green\", label=\"Real data\")\n    blue_patch = mpatches.Patch(color=\"blue\", label=\"Fake data\")\n    plt.legend(handles=[green_patch, blue_patch])\n  # Plot only original data\n  else:\n    plt.scatter(principal_real_data[\"principal_component_1\"], principal_real_data[\"principal_component_2\"], color=\"green\", s=70, alpha=0.3)\n    plt.title(\"2 principal components\")\n    plt.xlabel(\"component 1\")\n    plt.ylabel(\"component 2\")\n    green_patch = mpatches.Patch(color=\"green\", label=\"Real data\")\n    plt.legend(handles=[green_patch])"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["# Train GAN for 2 epochs and plot the real data\ngen_model, dis_model = train_gans(2)\nfake_data = generate_fake_data(gen_model)\nplot_pca(data, fake_data, True)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["# Plot real and fake data after 2 epochs\nplot_pca(data, fake_data, False)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["# Train the model for 10 epochs and plot the real and fake data\ngen_model, dis_model = train_gans(10)\nfake_data = generate_fake_data(gen_model)\nplot_pca(data, fake_data, False)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["### Conclusion ###\nIn practice, it is more popular to train GAN on image data. Since 2014, different researchers have come up with different techniques to train GAN on tabular data (for example, see https://arxiv.org/pdf/1907.00503.pdf). Although GAN as we have seen works to some extend, in practice it has some drawbacks whose solutions have been object of intensive research since the original 2014. The major drawbacks have to do with the **training of the GAN**.\n<br><br>\n\n\n0. Training a GAN is hyperparameter-dependent. \n0. The loss functions are not informative: while the generated samples may start to closely resemble the true data — approximating significantly its distribution — this behavior can’t be indexed to a trend of the losses in general. This means that we can’t just run a hyperparameter optimizer using the losses and must instead iteratively tune them manually.\n0. Generating categorical data is a particularly difficult problem for GANs."],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{}}],"metadata":{"name":"DL 10 - Generative Adversarial Networks","notebookId":1391719663530955},"nbformat":4,"nbformat_minor":0}
