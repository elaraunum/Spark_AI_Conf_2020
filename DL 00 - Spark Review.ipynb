{"cells":[{"cell_type":"markdown","source":["d-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 1200px\">\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["# Spark Review\n\nBefore we get started with Machine Learning and Deep Learning, let's make sure we all understand how to use Databricks and Spark.\n\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) In this lesson you:<br>\n - Create a Spark DataFrame\n - Analyze the Spark UI\n - Cache data\n - Go between Pandas and Spark DataFrames"],"metadata":{}},{"cell_type":"markdown","source":["![](https://files.training.databricks.com/images/spark_cluster_tasks.png)"],"metadata":{}},{"cell_type":"markdown","source":["Let's start off with running some code on our driver, such as `x = 1`. Insert a new cell below."],"metadata":{}},{"cell_type":"markdown","source":["## Spark DataFrame\n\nGreat! Now let's start with a distributed Spark DataFrame."],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.functions import col, rand\n\ndf = (spark.range(1, 1000000)\n      .withColumn('id', (col('id') / 1000).cast('integer'))\n      .withColumn('v', rand(seed=1)))"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["Why were no Spark jobs kicked off above? Well, we didn't have to actually \"touch\" our data, so Spark didn't need to execute anything across the cluster."],"metadata":{}},{"cell_type":"code","source":["display(df.sample(.001))"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["## Count\n\nLet's see how many records we have."],"metadata":{}},{"cell_type":"code","source":["df.count()"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["## Spark UI\n\nOpen up the Spark UI - what are the shuffle read and shuffle write fields? The command below should give you a clue."],"metadata":{}},{"cell_type":"code","source":["df.rdd.getNumPartitions()"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["## Cache\n\nFor repeated access, it will be much faster if we cache our data."],"metadata":{}},{"cell_type":"code","source":["df.cache().count()"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["## Re-run Count\n\nWow! Look at how much faster it is now!"],"metadata":{}},{"cell_type":"code","source":["df.count()"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["## Pandas\n\nLet's convert our Spark DataFrame to a Pandas DataFrame."],"metadata":{}},{"cell_type":"code","source":["df.toPandas()"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["## Wrap-up\n\nAlright! Now that you know the basics of Spark, let's get started!"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{}}],"metadata":{"name":"DL 00 - Spark Review","notebookId":1391719663531888},"nbformat":4,"nbformat_minor":0}
