{"cells":[{"cell_type":"markdown","source":["d-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 1200px\">\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["# Transfer Learning\n\nThe idea behind transfer learning is to take knowledge from one model doing some task, and transfer it to build another model doing a similar task.\n\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) In this lesson you:<br>\n - Motivate why transfer learning is a promising frontier for deep learning \n - Compare transfer learning approaches\n - Perform transfer learning to create an cat vs dog vs founder classifier"],"metadata":{}},{"cell_type":"code","source":["%run \"./Includes/Classroom-Setup\""],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["### Why Transfer Learning\n\nIn 2016, Andrew Ng claimed that transfer learning will be the next driver of commercial machine learning success after supervised learning.  Why?<br><br>\n\n- A fundamental assumption of most machine learning approaches is that you train a model from scratch on a new dataset\n- Transfer learning stores knowledge gained from solving one problem on a different, related problem\n- More closely resembles human learning\n\nWhat types of features could be transfered from one task to the next in the following cases?<br><br>\n\n- Image recognition\n- Natural language processing\n- Speech recognition\n- Time series"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n### Common Pre-Trained Models\n\nKeras exposes a number of deep learning models (architectures) along with pre-trained weights.  They are available in the `tensorflow.keras.applications` package and [the full list is available here.](https://www.tensorflow.org/api_docs/python/tf/keras/applications)  \n\nTransfer learning...<br><br>\n\n- Saves a lot of time and resources over retraining models from scratch\n- Are often pre-trained using the ImageNet dataset\n- Repurposes earlier layers that encode higher level features (e.g. edges in images)\n- Uses custom final layers specific to the new task\n\nBelow is a comparison of common reference architectures and pre-trained weights used in transfer learning:\n\n| Network | Year | ImageNet Accuracy | # of Params | Floating Point Operations |\n|---------|------|-------------------|-------------|---------------------------|\n| AlexNet | 2012 | 84.7% | 62M | 1.5B | \n| VGGNet | 2014 | 92.3% | 138M | 19.6B | \n| Inception | 2014 | 93.3% | 6.4M | 2B | \n| ResNet-152 | 2015 | 95.5% | 60.3M | 11B | \n\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> [See this article for a full comparison.](https://towardsdatascience.com/the-w3h-of-alexnet-vggnet-resnet-and-inception-7baaaecccc96)"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n### The Implementation Details\n\nWe want to make a classifier that distinguishes between Databricks founders and the pets of Databricks employees. To do this, we'll use VGG16, but instead of predicting 1000 classes, we will predict 3 classes (cat, dog, or cofounder).  We have 3 options:<br><br>\n\n1. Use **only the architecture from VGG16**, initialize the weights at random. This is a computationally expensive approach and requires a lot of data as you are training hundreds of millions of weights from scratch.\n2. Use **both the architecture from VGG16 and weights** pre-trained on ImageNet.  Leave earlier layers frozen and retrain the later layers.  This is less computationally expensive and still requires a good amount of data.\n3. Use both the architecture from VGG16 and the weights, but **freeze the entire network, and add an additional layer.**  In this case, we would only train the final classification layer specific to our problem.  This is fast and works with small amounts of data.\n\nSince our dataset is small and similar to the task VGG16 was trained on, we'll choose option 3.\n\n<img alt=\"Best Practice\" title=\"Best Practice\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.3em\" src=\"https://files.training.databricks.com/static/images/icon-blue-ribbon.svg\"/> Would you want to use a high or low learning rate for transfer learning? Or different learning rates for different layers?"],"metadata":{}},{"cell_type":"markdown","source":["Notice how few images we have in our training data. Will our neural network be able to distinguish between animals and founders?"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.functions import lit\n\ndf_cats = spark.read.format(\"image\").load(\"/mnt/training/dl/img/cats/*.jpg\").withColumn(\"label\", lit(\"cat\"))\ndf_dogs = spark.read.format(\"image\").load(\"/mnt/training/dl/img/dogs/*.jpg\").withColumn(\"label\", lit(\"dog\"))\ndf_founder = spark.read.format(\"image\").load(\"/mnt/training/dl/img/founders/*\").withColumn(\"label\", lit(\"founder\"))\n\ndisplay(df_cats)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["Do a custom train/test split to make sure there are stratified samples."],"metadata":{}},{"cell_type":"code","source":["cat_data = df_cats.toPandas()\ndog_data = df_dogs.toPandas()\nfounder_data = df_founder.toPandas()\n\ntrain_data = cat_data.iloc[:5].append(dog_data.iloc[:5]).append(founder_data.iloc[:4])\ntrain_data[\"path\"] = train_data[\"image\"].apply(lambda x: x[\"origin\"].replace(\"dbfs:/\",\"/dbfs/\"))\n\ntest_data = cat_data.iloc[5:].append(dog_data.iloc[5:]).append(founder_data.iloc[4:])\ntest_data[\"path\"] = test_data[\"image\"].apply(lambda x: x[\"origin\"].replace(\"dbfs:/\",\"/dbfs/\"))\n\nprint(f\"Train data samples: {len(train_data)} \\tTest data samples: {len(test_data)}\")"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["Here we use Keras functional API. The Keras functional API is a way to create models that is more flexible than the tf.keras.Sequential API. The functional API can handle models with non-linear topology, models with shared layers, and models with multiple inputs or outputs. The main idea that a deep learning model is usually a directed acyclic graph (DAG) of layers. So the functional API is a way to build graphs of layers."],"metadata":{}},{"cell_type":"code","source":["import tensorflow as tf\nfrom tensorflow.keras import applications\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model \nfrom tensorflow.keras.layers import Dense\ntf.random.set_seed(42)\n\nimg_height = 224\nimg_width = 224\n\n# Load original model with pretrained weights from imagenet\nmodel = applications.VGG16(weights=\"imagenet\", input_shape=(img_height, img_width, 3))\n\n# Freeze all previous layers\nmodel.trainable = False \n    \n# Add custom new layer for 3 classes\nx = model.output\npredictions = Dense(3, activation=\"softmax\")(x)\n\nmodel_final = Model(inputs=model.input, outputs=predictions)\nmodel_final.summary()"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["Now we only have to train 3,003 parameters instead of the 138,360,547 present in our network architecture. \n\nTo train the model, we use [ImageDataGenerator](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) class. Generators are useful when your data is very large, as you only need to load one batch of data into memroy at a time. In general, ImageDataGenerator is used to configure random transformations and normalization operations to be done on your image data during training, as well as instantiate generators of augmented image batches (and their labels). \n\nThese generators can be used with Keras model methods that accept data generators as inputs. [flow_from_dataframe()](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow_from_dataframe) takes the dataframe and the path to a directory to generates batches."],"metadata":{}},{"cell_type":"code","source":["import mlflow.tensorflow\n\n# Check out the MLflow UI as this runs\nmlflow.tensorflow.autolog(every_n_iter=2)\n\nmodel_final.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n\n# Loading training data\nbatch_size = 2\ntrain_datagen = ImageDataGenerator(preprocessing_function=applications.vgg16.preprocess_input)\ntrain_generator = train_datagen.flow_from_dataframe(dataframe=train_data, \n                                                    directory=None, \n                                                    x_col=\"path\", \n                                                    y_col=\"label\", \n                                                    class_mode=\"categorical\", \n                                                    target_size=(img_height, img_width), \n                                                    batch_size=batch_size)\n\nprint(f\"Class labels: {train_generator.class_indices}\")\n\nstep_size = train_generator.n//train_generator.batch_size\n\n# Train the model \nmodel_final.fit(train_generator, epochs=10, steps_per_epoch=step_size, verbose=2)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["## Evaluate the Accuracy"],"metadata":{}},{"cell_type":"code","source":["# Evaluate model on test set\ntest_datagen = ImageDataGenerator(preprocessing_function=applications.vgg16.preprocess_input)\n\n# Small dataset so we can evaluate it in one batch\nbatch_size = 8\n\ntest_generator = test_datagen.flow_from_dataframe(\n  dataframe=test_data, \n  directory=None, \n  x_col=\"path\", \n  y_col=\"label\", \n  class_mode=\"categorical\", \n  target_size=(img_height, img_width),\n  shuffle=False,\n  batch_size=batch_size\n)\n\nstep_size = test_generator.n//test_generator.batch_size\n\neval_results = model_final.evaluate(test_generator, steps=step_size)\nprint(f\"Loss: {eval_results[0]}. Accuracy: {eval_results[1]}\")"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["## Visualize the Results"],"metadata":{}},{"cell_type":"code","source":["import pandas as pd\n\npredictions = pd.DataFrame({\n  \"Prediction\": model_final.predict(test_generator, steps=step_size).argmax(axis=1),\n  \"True\": test_generator.classes,\n  \"Path\": test_data[\"path\"].apply(lambda x: x.replace(\"/dbfs/\", \"dbfs:/\"))\n}).replace({v: k for k, v in train_generator.class_indices.items()})\n\nall_images_df = df_cats.union(df_dogs).union(df_founder).drop(\"label\")\npredictions_df = spark.createDataFrame(predictions)\n\ndisplay(all_images_df.join(predictions_df, predictions_df.Path==all_images_df.image.origin))\n"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{}}],"metadata":{"name":"DL 09 - Transfer Learning","notebookId":1391719663531239},"nbformat":4,"nbformat_minor":0}
