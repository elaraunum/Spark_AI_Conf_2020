{"cells":[{"cell_type":"markdown","source":["d-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 1200px\">\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["# SARSA Control - Gridworld Problem\n\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) In this lab you learn:<br>\n - Finding Optimal Policy Using SARSA"],"metadata":{}},{"cell_type":"markdown","source":["### Problem Statement ###\n\nIn this lab we are going to find an optimal policy. Keep in mind that we do NOT know the dynamic of the environment nor are we given the MDP i.e. this is the full RL prediction problem. We created an environment for this gridworld problem earlier. We are going to use that environment to develop SARSA algorithm to find optimal policy.\n\n![Prediction](https://files.training.databricks.com/images/rl/prediction.png)"],"metadata":{}},{"cell_type":"code","source":["%run \"./helper/GridWorldEnvironment\""],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["environment = GridWorldEnvironment()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# ANSWER\nimport numpy as np\nimport random\nnp.random.seed(1234)\n\ndef pick_action(Q, na, epsilon=0.1):\n  \"\"\"This function picks the greedy action according to e-greedy algorithm.\"\"\"\n  \n  actions = set([0,1,2,3])\n  \n  # Pick the greedy action with probability greater than epsilon/na \n  if np.random.rand() >= epsilon/na :\n    return np.argmax(Q)\n  # Pick a non-greedy action with a probability of epsilon/na \n  else:\n    return random.sample(actions - set([np.argmax(Q)]), 1)[0]\n      \n\ndef sarsa(gamma=1.0, epsilon=0.1, alpha=0.1, number_of_iterations=100000):\n  \"\"\"This function implements SARSA algorithm.\"\"\"\n  \n  # Number of states and actions\n  ns = 16\n  na = 4\n  # Number of time steps\n  time_step = 1000\n  # Initialize Q(S,A). We do not know the values. \n  Q = np.zeros([ns, na])\n  \n  # Create samples of episodes\n  for i in range(number_of_iterations):\n    if i%10000 == 0:\n      print(f\"This is iteration {i+1}\")\n    # Initial start point\n    start_state_index = random.randint(1,14)\n    action_index = pick_action(Q[start_state_index][:], na)\n    environment.set_state(start_state_index)\n    \n    for j in range(time_step):\n      # Take an action and observe next state, reward and whether or not we are at the terminal points\n      next_state, reward, is_done, _ = environment.step(action_index)\n      \n      next_action_index = pick_action(Q[next_state][:], na)\n      # Update the Q\n      Q[start_state_index][action_index] = Q[start_state_index][action_index] + alpha * (reward + gamma * Q[next_state][next_action_index] - Q[start_state_index][action_index])\n      \n      # Leave the loop if at terminal points\n      if is_done:\n        break\n      start_state_index = next_state\n      action_index = next_action_index\n    \n  return Q"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["Q = sarsa()"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["# Test your code\nvalue_expected = [[ 0.0,  0.0,  0.0,  0.0],\n       [-2.0, -3.0, -3.0, -1.0],\n       [-3.0, -4.0, -4.0, -2.0],\n       [-4.1, -4.0, -3.3, -3.1],\n       [-1.0, -3.0, -3.0, -2.0],\n       [-2.0, -4.0, -4.0, -2.3],\n       [-3.3, -3.0, -3.0, -3.0],\n       [-4.0, -3.0, -2.0, -4.0],\n       [-2.0, -4.0, -4.0, -3.0],\n       [-3.0, -3.0, -3.0, -3.0],\n       [-4.0, -2.0, -2.0, -4.0],\n       [-3.0, -2.0, -1.0, -3.0],\n       [-3.0, -3.0, -4.0, -4.0],\n       [-4.0, -2.0, -3.0, -4.0],\n       [-3.1, -1.0, -2.0, -3.0],\n       [ 0.0,  0.0,  0.0,  0.0]]  \n\nnp.testing.assert_array_almost_equal(Q, value_expected, err_msg = \"The values are incorrect\", decimal = 0)\n"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{}}],"metadata":{"name":"RL 05La - SARSA Lab - Gridworld Problem","notebookId":2929930686998323},"nbformat":4,"nbformat_minor":0}
