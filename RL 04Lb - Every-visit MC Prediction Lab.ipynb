{"cells":[{"cell_type":"markdown","source":["d-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 1200px\">\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["# Model-free Prediction (every-visit MC) \n\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) In this lab you learn:<br>\n - MC every-visit update"],"metadata":{}},{"cell_type":"markdown","source":["### Problem statement ###\n\nConsider the random walk problem on a straight line (1D) with 7 states. States t1, a, b, c, d, e, t2. Assume two end states, t1 and t2, are terminal states. If you end up there, the episode is over. If you reach t2, you are rewarded $100. If you reach t1, you are rewarded $0. There is a 50% chance of going right or left when you are at state a, b, c, d and e."],"metadata":{}},{"cell_type":"markdown","source":["### Exercise ###\nAssume you start at state c and \\\\(\\gamma = 1\\\\). Use every-visit MC to estimate the value of each state."],"metadata":{}},{"cell_type":"code","source":["%run \"./helper/MonteCarloEnvironment\""],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# ANSWER\ndef mc_every_visit_value(episodes):\n  \"\"\"This function calculate first-visit MC.\"\"\"\n \n  \n  value_a = value_b = value_c = value_d = value_e = 0.5\n  reward_t2 = 100\n  reward_t1 = 0\n  \n  return_a = []\n  return_b = []\n  return_c = []\n  return_d = []\n  return_e = []\n  \n  # Loop through episodes and states to update return_a, return_b, return_c, return_d, return_e\n  \n  for i in range(len(episodes)):\n    for j in episodes[i]:\n      \n      if j == 1.0 and episodes[i][-1] == 6:\n        return_a.append(reward_t2)\n      elif j == 1.0 and episodes[i][-1] == 0: \n        return_a.append(reward_t1)\n        \n      \n      elif j == 2.0 and episodes[i][-1] == 6:\n        return_b.append(reward_t2)\n        \n      elif j == 2.0 and episodes[i][-1] == 0:\n        return_b.append(reward_t1)\n        \n        \n      elif j == 3.0 and episodes[i][-1] == 6:\n        return_c.append(reward_t2)\n        \n      elif j == 3.0 and episodes[i][-1] == 0:\n        return_c.append(reward_t1)\n        \n        \n      elif j == 4.0 and episodes[i][-1] == 6:\n        return_d.append(reward_t2)\n        \n      elif j == 4.0 and episodes[i][-1] == 0:\n        return_d.append(reward_t1)\n        \n        \n      elif j == 5.0 and episodes[i][-1] == 6:\n        return_e.append(reward_t2)\n        \n      elif j == 5.0 and episodes[i][-1] == 0:\n        return_e.append(reward_t1)\n        \n        \n    value_a = mean(return_a) if len(return_a) !=0  else value_a\n    value_b = mean(return_b) if len(return_b) !=0  else value_b\n    value_c = mean(return_c) if len(return_c) !=0  else value_c\n    value_d = mean(return_d) if len(return_d) !=0  else value_d\n    value_e = mean(return_e) if len(return_e) !=0  else value_e\n      \n  return [value_a, value_b, value_c, value_d, value_e]"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["# Test your code\nepisodes = monte_carlo(5000)\nvalue = mc_every_visit_value(episodes) \nvalue_expected = [17.0, 33.0, 50.0, 67.0, 83.0] \nnp.testing.assert_array_almost_equal(value, value_expected, err_msg = \"The values are incorrect\", decimal = 0)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["### Bonus ###\nImplement incremental MC"],"metadata":{}},{"cell_type":"code","source":["# ANSWER\ndef mc_every_visit_incremental(episodes):\n  \"\"\"This function calculate first-visit MC.\"\"\"\n  \n  \n  reward_t2 = 100\n  reward_t1 = 0\n  values_old = [0, 0.5, 0.5, 0.5, 0.5, 0.5, 0 ]\n  values_new = [0, 0.5, 0.5, 0.5, 0.5, 0.5, 0 ]\n  rewards = [reward_t1, 0 ,0, 0, 0, 0, reward_t2]\n  count = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n  \n  # Loop through episodes and states to update return_a, return_b, return_c, return_d, return_e\n  \n  for i in range(len(episodes)):\n    \n    for j in list(episodes[i]):\n      if j != 0 and j != 6:\n        if episodes[i][-1] == 0:\n          count[j] += 1\n          values_new[j] = values_old[j] + 1.0/count[j] * (rewards[0] - values_old[j])\n          values_old[j] = values_new[j]\n        \n        if episodes[i][-1] == 6:\n          count[j] += 1\n          values_new[j] = values_old[j] + 1.0/count[j] * (rewards[6] - values_old[j])\n          values_old[j] = values_new[j]\n          \n        \n      else:\n        break\n        \n  return values_new"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["# Test your code\nepisodes = monte_carlo(10000)\nvalue = mc_every_visit_incremental(episodes) \nvalue_expected = [0.0, 16.0, 33.0, 50.0, 67.0, 83.0, 0.0]\nnp.testing.assert_array_almost_equal(value, value_expected, err_msg = \"The values are incorrect\", decimal = 0)\n"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{}}],"metadata":{"name":"RL 04Lb - Every-visit MC Prediction Lab","notebookId":2929930686998228},"nbformat":4,"nbformat_minor":0}
